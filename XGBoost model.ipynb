{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxtOBqFMqo3i"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import datetime\n",
    "from fastai.tabular import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_log_error as msle, mean_squared_error as mse\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7xgI4BQe1csf"
   },
   "outputs": [],
   "source": [
    "# Fill missing values with median \n",
    "def FillMissing(df):\n",
    "  for col in df.columns:\n",
    "    if pd.isnull(df[col]).sum():\n",
    "      filler = df[col].median()\n",
    "      df[col] = df[col].fillna(filler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAVL1-y7wtEp"
   },
   "outputs": [],
   "source": [
    "# Predictions lower than zero are turned zero\n",
    "def fix_predictions(y):\n",
    "    \"\"\"\n",
    "    :param y: Column with predictions\n",
    "    \"\"\"\n",
    "    y[y < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGJwTu5JgOT0"
   },
   "outputs": [],
   "source": [
    "# Predictibility in our predictions\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    :param seed: Value for seeding random functions\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNZ2XTAuxVXp"
   },
   "outputs": [],
   "source": [
    "seed = 5\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2-9F4ZTq6wf"
   },
   "outputs": [],
   "source": [
    "# Reducing memory usage, based on: https://www.kaggle.com/bwilsonkg/column-statistics\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\"\"\" \n",
    "Evaluation metric used in this competition: \n",
    "https://www.kaggle.com/c/ashrae-energy-prediction/overview/evaluation\n",
    "\"\"\"\"\n",
    "def rmsle(y_true: pd.Series, y_predict: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate root mean squared log error\n",
    "    :param y_true:\n",
    "    :param y_predict:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.sqrt(msle(y_true, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need this to download datasets from kaggle \n",
    "! {sys.executable} -m pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w2GA5QhTq4AW"
   },
   "outputs": [],
   "source": [
    "# Upload your credentials. You can donwload the API token from your kaggle account\n",
    "! mkdir -p ~/.kaggle/\n",
    "! mv kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "753UYCHcrS_s",
    "outputId": "08434d84-729d-4e7e-dd86-c2ef1b6e5ca6"
   },
   "outputs": [],
   "source": [
    "path = Config.data_path()/'ASHRAE'\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "mIJJrdtbrXtT",
    "outputId": "7bd8caf9-002f-4444-b828-c55c3a000776"
   },
   "outputs": [],
   "source": [
    "# Download data competition \n",
    "! kaggle competitions download -c ashrae-energy-prediction -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip files\n",
    "! unzip -q -n {path}/'ashrae-energy-prediction.zip' -d {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Sb1HSTLErm21",
    "outputId": "747ba3df-6dc3-4893-b729-e243255ee9f6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\" \n",
    "Read data to df. Note that we are using only \n",
    "training data in this notebook. \n",
    "We will use the test data for our predicitons \n",
    "and submission later in a separated notebook.\n",
    "\"\"\"\"\n",
    "build = reduce_mem_usage(pd.read_csv(path/'building_metadata.csv'))\n",
    "train = reduce_mem_usage(pd.read_csv(path/'train.csv'))\n",
    "weather_train = reduce_mem_usage(pd.read_csv(path/'weather_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "Rpb4dHTHM9TD",
    "outputId": "fbf06cf9-383a-4806-cf00-a934c42673f6"
   },
   "outputs": [],
   "source": [
    "FillMissing(train)\n",
    "FillMissing(build)\n",
    "FillMissing(weather_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJkCV2Juq3dA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "We perform a lag feature transformation.\n",
    "Lag features are the classical way that \n",
    "time series forecasting problems are \n",
    "transformed into supervised learning problems.\n",
    "Further reading:\n",
    "https://machinelearningmastery.com/basic-feature-engineering-time-series-data-python/\n",
    "\"\"\"\"\n",
    "def add_lag_feature(weather_df, window=3):\n",
    "    group_df = weather_df.groupby('site_id')\n",
    "    cols = ['air_temperature'] \n",
    "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
    "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "    lag_min = rolled.min().reset_index().astype(np.float16)\n",
    "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "    for col in cols:\n",
    "        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n",
    "        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n",
    "        weather_df[f'{col}_std_lag{window}'] = lag_std[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCMOE5H6X9P9"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Transform some data into a more meaningful feature.\n",
    "For example we transform the wind speed into Beaufort\n",
    "scale: https://es.wikipedia.org/wiki/Escala_de_Beaufort,\n",
    "or wind direction into compass direction:\n",
    "https://en.wikipedia.org/wiki/Points_of_the_compass\n",
    "\"\"\"\"\n",
    "def prepare_data(train,build,weather):\n",
    "   \n",
    "    add_lag_feature(weather, window=72)\n",
    "    train = train.merge(build, on='building_id',how='left')  \n",
    "    train = train.merge(weather, on=['site_id', 'timestamp'], how='left')\n",
    "    train['timestamp'] = pd.to_datetime(arg=train['timestamp'])\n",
    "        \n",
    "    train['year'] = train['timestamp'].dt.year\n",
    "    train['month'] = train['timestamp'].dt.month\n",
    "    train['day'] = train['timestamp'].dt.day\n",
    "    train['hour'] = train['timestamp'].dt.hour\n",
    "    train['weekday'] = train['timestamp'].dt.weekday\n",
    "    \n",
    "    train = reduce_mem_usage(train)\n",
    "\n",
    "    beaufort = [(0, 0, 0.3), (1, 0.3, 1.6), (2, 1.6, 3.4), (3, 3.4, 5.5), (4, 5.5, 8), (5, 8, 10.8), (6, 10.8, 13.9), \n",
    "          (7, 13.9, 17.2), (8, 17.2, 20.8), (9, 20.8, 24.5), (10, 24.5, 28.5), (11, 28.5, 33), (12, 33, 200)]\n",
    "    \n",
    "    for item in beaufort:\n",
    "        train.loc[(train['wind_speed']>=item[1]) & (train['wind_speed']<item[2]), 'beaufort_scale'] = item[0]\n",
    "    \n",
    "    #oktas = [('SKC', 0.0, 0.0), ('FEW', 1.0, 2.0), ('SCT', 3.0, 4.0), ('BKN', 5.0, 7.0), ('OVC', 8.0, 8.0), ('SOV', 9.0, 9.0)]\n",
    "\n",
    "    #for item in oktas:\n",
    "      #train.loc[(train['cloud_coverage']==item[1] and item[2]) | ((train['cloud_coverage']>=item[1]) & (train['cloud_coverage']<=item[2])),'oktas_scale'] = item[0]\n",
    "\n",
    "    compass = [('N', 360, 0), ('NbE', 0, 16.875), ('NNE', 16.875, 28.125), ('NEbN', 28.125, 39.375), ('NE', 39.375, 50.625), \n",
    "              ('NEbE', 50.625, 61.875), ('ENE', 61.875, 73.125), ('EbN', 73.125, 84.375), ('E', 84.375, 95.625), ('EbS', 95.625, 106.875),\n",
    "              ('ESE', 106.875, 118.125), ('SEbE', 118.125, 129.375), ('SE', 129.375, 140.625), ('SEbS', 140.625, 151.875), ('SSE', 151.875, 163.125),\n",
    "              ('SbE', 163.125, 174.375), ('S',174.375, 185.625), ('SbW', 185.625, 196.875), ('SSW', 196.875, 208.125), ('SWbS', 208.125, 219.375), \n",
    "              ('SW', 219.375, 230.625), ('SWbW', 230.625, 241.875), ('WSW', 241.875, 253.125), ('WbS', 253.125, 264.375), ('W', 264.375, 275.625), \n",
    "              ('WbN', 275.625, 286.875), ('WNW', 286.875, 298.125), ('NWbW', 298.125, 309.375), ('NW', 309.375, 320.625), ('NWbN', 320.625, 331.875), \n",
    "              ('NNW', 331.875, 343.125), ('NbW', 343.125, 360)]\n",
    "\n",
    "    for item in compass:  \n",
    "      train.loc[(train['wind_direction']>=item[1]) & (train['wind_direction']<item[2]), 'compass_direction'] = item[0]\n",
    "\n",
    "    comfort = [('Pleasant', -35.0, 12.7778), ('Comfy', 12.7778 , 15.5556), ('Sticky', 15.5556, 18.3333), ('Uncomfy', 18.3333, 21.1111), \n",
    "              ('Oppressive', 21.1111, 23.8889), ('Miserable', 23.8889, 26.1)] \n",
    "    \n",
    "    for item in comfort:\n",
    "      train.loc[(train['dew_temperature']>=item[1]) & (train['dew_temperature']<item[2]), 'comfort'] = item[0]\n",
    "    \n",
    "    train['age'] = train['year'] - train['year_built']\n",
    "    train = reduce_mem_usage(train)\n",
    "\n",
    "    return train\n",
    "    #if not test:\n",
    "        #X = X.query('not(site_id==0 & timestamp<\"2016-05-21 00:00:00\")')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VQUWe8x243O7",
    "outputId": "68f2e2ae-ac32-4a97-dc09-81f270ac78e8"
   },
   "outputs": [],
   "source": [
    "train = prepare_data(train,build,weather_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beLLvg3fZ2YE"
   },
   "outputs": [],
   "source": [
    "# Delete outliers as we decide in our previous EDA notebook\n",
    "train = train[train.building_id != 778] \n",
    "train = train[train.building_id != 1088] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "LpBBpvO13X_B",
    "outputId": "36fa2f04-f66a-476a-9386-5d5ab68867bf"
   },
   "outputs": [],
   "source": [
    "# Check our data in dataframe\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVnuvDaom9pq"
   },
   "outputs": [],
   "source": [
    "# Defining our variables(features) as continous or categoricals and prediction target.\n",
    "numericals = [\"square_feet\", 'precip_depth_1_hr','air_temperature_mean_lag72', 'air_temperature_max_lag72', 'primary_use' \n",
    "              'air_temperature_min_lag72', 'air_temperature_std_lag72', 'site_id', 'building_id', 'cloud_coverage', 'age']\n",
    "\n",
    "categoricals = [\"hour\", \"weekday\", \"meter\",'comfort','floor_count', 'month', 'compass_direction'] #'oktas_scale'\n",
    "target = 'meter_reading'\n",
    "features = categoricals + numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96Fw-n64QSLl"
   },
   "outputs": [],
   "source": [
    "# Transform categoricals features into category\n",
    "def Type(train):\n",
    " for col in train[categoricals]: \n",
    "  train[col] = train[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SB6VUqQmyRIx"
   },
   "outputs": [],
   "source": [
    "# Log + 1 transform of target input\n",
    "train[target] = np.log1p(train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Further information of Cross-Validation methods:\n",
    "https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "55ybu8w82lwl",
    "outputId": "ff2f357f-29bd-45fe-c9e7-6017dadcea10"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "XGB Parameters see lightgbm documentation:\n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html\"\"\"\n",
    "params = {\n",
    "    'min_child_weight': 10.0,\n",
    "    'objective': 'reg:squaredlogerror',\n",
    "    'max_depth': 7,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.025,\n",
    "    'gamma': 0.65,\n",
    "    'num_boost_round' : 700 \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVTa5NAV4T6U"
   },
   "source": [
    "**KStratfold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "GUQEs5W4OAqG",
    "outputId": "e2d0ba99-b2f4-448f-b7d2-97beaab124ff"
   },
   "outputs": [],
   "source": [
    "folds = 2\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "for train_index, val_index in kf.split(train, train['building_id']):\n",
    "  train_X = train[features].iloc[train_index]\n",
    "  val_X = train[features].iloc[val_index]\n",
    "  train_y = train[target].iloc[train_index]\n",
    "  val_y = train[target].iloc[val_index]\n",
    "  xgb_train = xgb.DMatrix(train_X, train_y)\n",
    "  xgb_eval = xgb.DMatrix(val_X, val_y)\n",
    "  gbm = xgb.train(params,\n",
    "                 xgb_train,\n",
    "                 num_boost_round=2500,\n",
    "                 valid_sets=(xgb_train, xgb_eval),\n",
    "                 early_stopping_rounds=150,\n",
    "                 verbose_eval = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.save_model('lgb_classifier_{}_{}.txt'.format(datetime.datetime.now().strftime(\"%d-%m-%Y\"), rmsle), num_iteration=gbm.best_iteration)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ML_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
